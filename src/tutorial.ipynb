{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arthurflor23/handwritten-text-recognition/blob/master/src/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gP-v0E_S-mQP"
   },
   "source": [
    "<img src=\"https://github.com/arthurflor23/handwritten-text-recognition/blob/master/doc/image/header.png?raw=true\" />\n",
    "\n",
    "# Handwritten Text Recognition using TensorFlow 2.0\n",
    "\n",
    "This tutorial shows how you can use the project [Handwritten Text Recognition](https://github.com/arthurflor23/handwritten-text-recognition) in your Google Colab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oMty1YwuWHpN"
   },
   "source": [
    "## 1 Localhost Environment\n",
    "\n",
    "We'll make sure you have the project in your Google Drive with the datasets in HDF5. If you already have structured files in the cloud, skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "39blvPTPQJpt"
   },
   "source": [
    "### 1.1 Datasets\n",
    "\n",
    "The datasets that you can use:\n",
    "\n",
    "a. [Bentham](http://transcriptorium.eu/datasets/bentham-collection/)\n",
    "\n",
    "b. [IAM](http://www.fki.inf.unibe.ch/databases/iam-handwriting-database)\n",
    "\n",
    "c. [Rimes](http://www.a2ialab.com/doku.php?id=rimes_database:start)\n",
    "\n",
    "d. [Saint Gall](http://www.fki.inf.unibe.ch/databases/iam-historical-document-database/saint-gall-database)\n",
    "\n",
    "e. [Washington](http://www.fki.inf.unibe.ch/databases/iam-historical-document-database/washington-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVBGMLifWQwl"
   },
   "source": [
    "### 1.2 Raw folder\n",
    "\n",
    "On localhost, download the code project from GitHub and extract the chosen dataset (or all if you prefer) in the **raw** folder. Don't change anything of the structure of the dataset, since the scripts were made from the **original structure** of them. Your project directory will be like this:\n",
    "\n",
    "```\n",
    ".\n",
    "├── raw\n",
    "│   ├── bentham\n",
    "│   │   ├── BenthamDatasetR0-GT\n",
    "│   │   └── BenthamDatasetR0-Images\n",
    "│   ├── iam\n",
    "│   │   ├── ascii\n",
    "│   │   ├── forms\n",
    "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
    "│   │   ├── lines\n",
    "│   │   └── xml\n",
    "│   ├── rimes\n",
    "│   │   ├── eval_2011\n",
    "│   │   ├── eval_2011_annotated.xml\n",
    "│   │   ├── training_2011\n",
    "│   │   └── training_2011.xml\n",
    "│   ├── saintgall\n",
    "│   │   ├── data\n",
    "│   │   ├── ground_truth\n",
    "│   │   ├── README.txt\n",
    "│   │   └── sets\n",
    "│   └── washington\n",
    "│       ├── data\n",
    "│       ├── ground_truth\n",
    "│       ├── README.txt\n",
    "│       └── sets\n",
    "└── src\n",
    "    ├── data\n",
    "    │   ├── evaluation.py\n",
    "    │   ├── generator.py\n",
    "    │   ├── preproc.py\n",
    "    │   ├── reader.py\n",
    "    │   ├── similar_error_analysis.py\n",
    "    ├── main.py\n",
    "    ├── network\n",
    "    │   ├── architecture.py\n",
    "    │   ├── layers.py\n",
    "    │   ├── model.py\n",
    "    └── tutorial.ipynb\n",
    "\n",
    "```\n",
    "\n",
    "After that, create virtual environment and install the dependencies with python 3 and pip:\n",
    "\n",
    "> ```python -m venv .venv && source .venv/bin/activate```\n",
    "\n",
    "> ```pip install -r requirements.txt```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WyLRbAwsWSYA"
   },
   "source": [
    "### 1.3 HDF5 files\n",
    "\n",
    "Now, you'll run the *transform* function from **main.py**. For this, execute on **src** folder:\n",
    "\n",
    "> ```python main.py --source=<DATASET_NAME> --transform```\n",
    "\n",
    "Your data will be preprocess and encode, creating and saving in the **data** folder. Now your project directory will be like this:\n",
    "\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── bentham.hdf5\n",
    "│   ├── iam.hdf5\n",
    "│   ├── rimes.hdf5\n",
    "│   ├── saintgall.hdf5\n",
    "│   └── washington.hdf5\n",
    "├── raw\n",
    "│   ├── bentham\n",
    "│   │   ├── BenthamDatasetR0-GT\n",
    "│   │   └── BenthamDatasetR0-Images\n",
    "│   ├── iam\n",
    "│   │   ├── ascii\n",
    "│   │   ├── forms\n",
    "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
    "│   │   ├── lines\n",
    "│   │   └── xml\n",
    "│   ├── rimes\n",
    "│   │   ├── eval_2011\n",
    "│   │   ├── eval_2011_annotated.xml\n",
    "│   │   ├── training_2011\n",
    "│   │   └── training_2011.xml\n",
    "│   ├── saintgall\n",
    "│   │   ├── data\n",
    "│   │   ├── ground_truth\n",
    "│   │   ├── README.txt\n",
    "│   │   └── sets\n",
    "│   └── washington\n",
    "│       ├── data\n",
    "│       ├── ground_truth\n",
    "│       ├── README.txt\n",
    "│       └── sets\n",
    "└── src\n",
    "    ├── data\n",
    "    │   ├── evaluation.py\n",
    "    │   ├── generator.py\n",
    "    │   ├── preproc.py\n",
    "    │   ├── reader.py\n",
    "    │   ├── similar_error_analysis.py\n",
    "    ├── main.py\n",
    "    ├── network\n",
    "    │   ├── architecture.py\n",
    "    │   ├── layers.py\n",
    "    │   ├── model.py\n",
    "    └── tutorial.ipynb\n",
    "\n",
    "```\n",
    "\n",
    "Then upload the **data** and **src** folders in the same directory in your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jydsAcWgWVth"
   },
   "source": [
    "## 2 Google Drive Environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wk3e7YJiXzSl"
   },
   "source": [
    "### 2.1 TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7twXyNGXtbJ"
   },
   "source": [
    "Make sure the jupyter notebook is using GPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHw4tODULT1Z"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJECz8H8XVCY"
   },
   "source": [
    "Now, we'll install TensorFlow 2.0 with GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FMg-B5PH9h3r"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-gpu==2.1.0-rc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w5ukHtpZiz0g"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name != \"/device:GPU:0\":\n",
    "    raise SystemError(\"GPU device not found\")\n",
    "\n",
    "print(f\"Found GPU at: {device_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FyMv5wyDXxqc"
   },
   "source": [
    "### 2.2 Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P5gj6qwoX9W3"
   },
   "source": [
    "Mount your Google Drive partition.\n",
    "\n",
    "**Note:** *\\\"Colab Notebooks/handwritten-text-recognition/src/\\\"* was the directory where you put the project folders, specifically the **src** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ACQn1iBF9k9O"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"./gdrive\", force_remount=True)\n",
    "\n",
    "%cd \"./gdrive/My Drive/Colab Notebooks/handwritten-text-recognition/src/\"\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwogUA8RZAyp"
   },
   "source": [
    "After mount, you can see the list os files in the project folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-fj7fSngY1IX"
   },
   "source": [
    "## 3 Set Python Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6Q4cOlWhNl3"
   },
   "source": [
    "### 3.1 Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wvqL2Eq5ZUc7"
   },
   "source": [
    "First, let's define our environment variables.\n",
    "\n",
    "Set the main configuration parameters, like input size, batch size, number of epochs and list of characters. This make compatible with **main.py** and jupyter notebook:\n",
    "\n",
    "* **dataset**: \"bentham\", \"iam\", \"rimes\", \"saintgall\", \"washington\"\n",
    "\n",
    "* **arch**: network to run: \"bluche\", \"puigcerver\", \"flor\"\n",
    "\n",
    "* **epochs**: number of epochs\n",
    "\n",
    "* **batch_size**: number size of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Qpr3drnGMWS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: ..\\data\\iam_words.hdf5\n",
      "output ..\\output\\iam_words\\simpleHTR\n",
      "target ..\\output\\iam_words\\simpleHTR\\checkpoint_weights.hdf5\n",
      "charset: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import string\n",
    "\n",
    "# define parameters\n",
    "source = \"iam_words\"\n",
    "arch = \"simpleHTR\"\n",
    "epochs = 1000\n",
    "batch_size = 16\n",
    "\n",
    "# define paths\n",
    "source_path = os.path.join(\"..\", \"data\", f\"{source}.hdf5\")\n",
    "output_path = os.path.join(\"..\", \"output\", source, arch)\n",
    "target_path = os.path.join(output_path, \"checkpoint_weights.hdf5\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# define input size, number max of chars per line and list of valid chars\n",
    "# input_size = (1024, 128, 1)\n",
    "# max_text_length = 128\n",
    "input_size = (128, 32, 1)\n",
    "max_text_length = 32\n",
    "charset_base = string.printable[:80]\n",
    "\n",
    "print(\"source:\", source_path)\n",
    "print(\"output\", output_path)\n",
    "print(\"target\", target_path)\n",
    "print(\"charset:\", charset_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BFextshOhTKr"
   },
   "source": [
    "### 3.2 DataGenerator Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfZ1mfvsanu1"
   },
   "source": [
    "The second class is **DataGenerator()**, responsible for:\n",
    "\n",
    "* Load the dataset partitions (train, valid, test);\n",
    "\n",
    "* Manager batchs for train/validation/test process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8k9vpNzMIAi2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 28143\n",
      "Validation images: 4088\n",
      "Test images: 10586\n"
     ]
    }
   ],
   "source": [
    "from data.generator import DataGenerator\n",
    "\n",
    "dtgen = DataGenerator(source=source_path,\n",
    "                      batch_size=batch_size,\n",
    "                      charset=charset_base,\n",
    "                      max_text_length=max_text_length)\n",
    "\n",
    "print(f\"Train images: {dtgen.size['train']}\")\n",
    "print(f\"Validation images: {dtgen.size['valid']}\")\n",
    "print(f\"Test images: {dtgen.size['test']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-OdgNLK0hYAA"
   },
   "source": [
    "### 3.3 HTRModel Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHktk8AFcnKy"
   },
   "source": [
    "The third class is **HTRModel()**, was developed to be easy to use and to abstract the complicated flow of a HTR system. It's responsible for:\n",
    "\n",
    "* Create model with Handwritten Text Recognition flow, in which calculate the loss function by CTC and decode output to calculate the HTR metrics (CER, WER and SER);\n",
    "\n",
    "* Save and load model;\n",
    "\n",
    "* Load weights in the models (train/infer);\n",
    "\n",
    "* Make Train/Predict process using *generator*.\n",
    "\n",
    "To make a dynamic HTRModel, its parameters are the *architecture*, *input_size* and *vocab_size*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nV0GreStISTR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 128, 32, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 128, 32, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 32, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 8, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 8, 128)        73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 8, 128)        512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 4, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 4, 128)        512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 2, 256)        295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32, 2, 256)        1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 1, 256)        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 32, 512)           1050624   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 32, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 512)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32, 83)            42579     \n",
      "=================================================================\n",
      "Total params: 3,239,251\n",
      "Trainable params: 3,238,035\n",
      "Non-trainable params: 1,216\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from network.model import HTRModel\n",
    "\n",
    "# create and compile HTRModel\n",
    "# note: `learning_rate=None` will get architecture default value\n",
    "model = HTRModel(architecture=arch, input_size=input_size, vocab_size=dtgen.tokenizer.vocab_size)\n",
    "model.compile(learning_rate=0.001)\n",
    "\n",
    "# save network summary\n",
    "model.summary(output_path, \"summary.txt\")\n",
    "\n",
    "# get default callbacks and load checkpoint weights file (HDF5) if exists\n",
    "model.load_checkpoint(target=target_path)\n",
    "\n",
    "callbacks = model.get_callbacks(logdir=output_path, checkpoint=target_path, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KASq6zqogG6Q"
   },
   "source": [
    "## 4 Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8eBxuoogM-d"
   },
   "source": [
    "To facilitate the visualization of the model's training, you can instantiate the Tensorboard. \n",
    "\n",
    "**Note**: All data is saved in the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPx4hRHuJGAd"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --reload_interval=300 --logdir={output_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T1fnz0Eugqru"
   },
   "source": [
    "## 5 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1mLOcqYgsO-"
   },
   "source": [
    "The training process is similar to the *fit()* of the Keras. After training, the information (epochs and minimum loss) is save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2P6MSoxCISlD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1759 steps, validate for 256 steps\n",
      "Epoch 1/1000\n",
      " 803/1759 [============>.................] - ETA: 50s - loss: 15.8346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0115 19:36:42.271182  7760 callbacks.py:1018] Can save best model only with val_loss available, skipping.\n",
      "W0115 19:36:42.272147  7760 callbacks.py:1286] Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "W0115 19:36:42.273143  7760 callbacks.py:1934] Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 804/1759 [============>.................] - ETA: 50s - loss: 15.8346"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4321e24f045a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m               verbose=1)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\work\\handwritten-text-recognition\\src\\network\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m                              \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m                              \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m                              use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# to calculate total and average time per epoch\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "h = model.fit(x=dtgen.next_train_batch(),\n",
    "              epochs=epochs,\n",
    "              steps_per_epoch=dtgen.steps['train'],\n",
    "              validation_data=dtgen.next_valid_batch(),\n",
    "              validation_steps=dtgen.steps['valid'],\n",
    "              callbacks=callbacks,\n",
    "              shuffle=True,\n",
    "              verbose=1)\n",
    "\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "loss = h.history['loss']\n",
    "val_loss = h.history['val_loss']\n",
    "\n",
    "min_val_loss = min(val_loss)\n",
    "min_val_loss_i = val_loss.index(min_val_loss)\n",
    "\n",
    "time_epoch = (total_time / len(loss))\n",
    "total_item = (dtgen.size['train'] + dtgen.size['valid'])\n",
    "\n",
    "t_corpus = \"\\n\".join([\n",
    "    f\"Total train images:      {dtgen.size['train']}\",\n",
    "    f\"Total validation images: {dtgen.size['valid']}\",\n",
    "    f\"Batch:                   {dtgen.batch_size}\\n\",\n",
    "    f\"Total time:              {total_time}\",\n",
    "    f\"Time per epoch:          {time_epoch}\",\n",
    "    f\"Time per item:           {time_epoch / total_item}\\n\",\n",
    "    f\"Total epochs:            {len(loss)}\",\n",
    "    f\"Best epoch               {min_val_loss_i + 1}\\n\",\n",
    "    f\"Training loss:           {loss[min_val_loss_i]:.8f}\",\n",
    "    f\"Validation loss:         {min_val_loss:.8f}\"\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"train.txt\"), \"w\") as lg:\n",
    "    lg.write(t_corpus)\n",
    "    print(t_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13g7tDjWgtXV"
   },
   "source": [
    "## 6 Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ddO26OT-g_QK"
   },
   "source": [
    "The predict process is similar to the *predict* of the Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9iHL6tmaL_j"
   },
   "outputs": [],
   "source": [
    "from data import preproc as pp\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# predict() function will return the predicts with the probabilities\n",
    "predicts, _ = model.predict(x=dtgen.next_test_batch(),\n",
    "                            steps=dtgen.steps['test'],\n",
    "                            ctc_decode=True,\n",
    "                            verbose=1)\n",
    "\n",
    "# decode to string\n",
    "predicts = [dtgen.tokenizer.decode(x[0]) for x in predicts]\n",
    "\n",
    "total_time = datetime.datetime.now() - start_time\n",
    "\n",
    "# mount predict corpus file\n",
    "with open(os.path.join(output_path, \"predict.txt\"), \"w\") as lg:\n",
    "    for pd, gt in zip(predicts, dtgen.dataset['test']['gt']):\n",
    "        lg.write(f\"TE_L {gt}\\nTE_P {pd}\\n\")\n",
    "   \n",
    "for i, item in enumerate(dtgen.dataset['test']['dt'][:10]):\n",
    "    print(\"=\" * 1024, \"\\n\")\n",
    "    cv2_imshow(pp.adjust_to_see(item))\n",
    "    print(dtgen.dataset['test']['gt'][i])\n",
    "    print(predicts[i], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9JcAs3Q3WNJ-"
   },
   "source": [
    "## 7 Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8LuZBRepWbom"
   },
   "source": [
    "Evaluation process is more manual process. Here we have the `ocr_metrics`, but feel free to implement other metrics instead. In the function, we have three parameters: \n",
    "\n",
    "* predicts\n",
    "* ground_truth\n",
    "* norm_accentuation (calculation with/without accentuation)\n",
    "* norm_punctuation (calculation with/without punctuation marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0gCwEYdKWOPK"
   },
   "outputs": [],
   "source": [
    "from data import evaluation\n",
    "\n",
    "evaluate = evaluation.ocr_metrics(predicts=predicts,\n",
    "                                  ground_truth=dtgen.dataset['test']['gt'],\n",
    "                                  norm_accentuation=False,\n",
    "                                  norm_punctuation=False)\n",
    "\n",
    "e_corpus = \"\\n\".join([\n",
    "    f\"Total test images:    {dtgen.size['test']}\",\n",
    "    f\"Total time:           {total_time}\",\n",
    "    f\"Time per item:        {total_time / dtgen.size['test']}\\n\",\n",
    "    f\"Metrics:\",\n",
    "    f\"Character Error Rate: {evaluate[0]:.8f}\",\n",
    "    f\"Word Error Rate:      {evaluate[1]:.8f}\",\n",
    "    f\"Sequence Error Rate:  {evaluate[2]:.8f}\"\n",
    "])\n",
    "\n",
    "with open(os.path.join(output_path, \"evaluate.txt\"), \"w\") as lg:\n",
    "    lg.write(e_corpus)\n",
    "    print(e_corpus)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "oMty1YwuWHpN"
   ],
   "name": "tutorial.ipynb",
   "provenance": []
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
